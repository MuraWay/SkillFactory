Kaggle: Dmitry Lepin
Значение метрики: 0.73461

Ноутбук создавался в среде Google Colab

В репозитории файлы из Kagggle:
sample_submission.csv
test.csv
train.csv

Результат работы модели: submission.csv

Pandas Profiling Report: report.html



Что не получилось:
1) Сдать работу в срок
2) Поэкспериментировать с другими моделями, кроме LogisticRegression
3) Побольше поэкспериментировать с разными алгоритмами балансировки
4) Победить в соревновании )))

Что получилось:
1) Убедиться, что самое главное в ML - подготовка данных. Обоснованные и вдумчивые изменения в признаках дают гораздо 
больший эффект, чем любые настройки параметров модели (до определённой степени, конечно).
2) Смастерить действующую модель
3) Подтянуть навыки в визуализации - matplotlib и  seaborn
4) Немного разобраться в азах sklearn

PS.
Несколько вопросов:
1) Основная сложность для меня была в том, что заранее невозможно предсказать как долго будут подбираться гиперпараметры, 
множество раз останавливал выполнение кода через несколько часов ))) Очевидно это придёт с опытом.
В связи с этим - есть ли некая неписаная норма - сколько времени должен занимать подбор гиперпараметров и обучение модели? 

2) penalty='l2' обрабатывается в разы быстрее, чем penalty='l2' - это всегда, или заивсит от чего-то?

3) При балансировке добавлением примеров миноритарного класса - сильно растёт значение logloss. Можно этого избежать?
Возможно я что-то делал не так?

Спасибо.